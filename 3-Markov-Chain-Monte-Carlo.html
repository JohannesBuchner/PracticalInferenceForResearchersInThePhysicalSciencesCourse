

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Markov Chain Monte Carlo &mdash; MCI-course 0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="_static/icon.ico"/>
  
  
  
    <link rel="canonical" href="https://johannesbuchner.github.io/UltraNest/3-Markov-Chain-Monte-Carlo.html"/>
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #2980B9" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MCI-course
          

          
            
            <img src="_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="preliminaries.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="install.html">Install</a></li>
<li class="toctree-l1"><a class="reference internal" href="BooksAndPapers.html">Reading material</a></li>
<li class="toctree-l1"><a class="reference internal" href="BooksAndPapers.html#Papers-for-Advanced-Methods">Papers for Advanced Methods</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MCI-course</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Markov Chain Monte Carlo</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Markov-Chain-Monte-Carlo">
<h1>Markov Chain Monte Carlo<a class="headerlink" href="#Markov-Chain-Monte-Carlo" title="Permalink to this headline">¶</a></h1>
<div class="section" id="Recap">
<h2>Recap<a class="headerlink" href="#Recap" title="Permalink to this headline">¶</a></h2>
<p>We have some target function (the likelihood times the prior) in some parameter space, and we want to integrate it.</p>
<p>As a toy example, we chose the following likelihood:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[63]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">loglikelihood</span><span class="p">(</span><span class="o">*</span><span class="n">parameters</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">parameters</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">parameters</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">*</span> <span class="mi">10</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>And we assume our prior is uniform in the domain -1/2 to +1/2 in each parameter. We use two parameters at the moment.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[64]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">lo</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span>
<span class="n">hi</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">dim</span> <span class="o">=</span> <span class="mi">2</span>
</pre></div>
</div>
</div>
<p>Lets plot this function in 2d:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[65]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">lo</span><span class="p">,</span> <span class="n">hi</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">lo</span><span class="p">,</span> <span class="n">hi</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>

<span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">grid_unnormalised_logposterior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">loglikelihood</span><span class="p">)(</span><span class="n">grid</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">grid</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span>
      <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">grid_unnormalised_logposterior</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
      <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="n">lo</span><span class="p">,</span> <span class="n">hi</span><span class="p">,</span> <span class="n">lo</span><span class="p">,</span> <span class="n">hi</span><span class="p">),</span>
      <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;equal&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray_r&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/3-Markov-Chain-Monte-Carlo_6_0.png" src="_images/3-Markov-Chain-Monte-Carlo_6_0.png" />
</div>
</div>
</div>
<div class="section" id="Markov-Chain-Monte-Carlo-intro">
<h2>Markov Chain Monte Carlo intro<a class="headerlink" href="#Markov-Chain-Monte-Carlo-intro" title="Permalink to this headline">¶</a></h2>
<p>In importance sampling, we used uncorrelated points.</p>
<div class="section" id="Important-terminology">
<h3>Important terminology<a class="headerlink" href="#Important-terminology" title="Permalink to this headline">¶</a></h3>
<p>Now we use an algorithm which produces a sequence of points: <span class="math notranslate nohighlight">\(\theta_1,\theta_2,...\theta_N\)</span>. We call this a <strong>chain</strong>.</p>
<p>A sequence of points where the next point <strong>only</strong> depends on the immediately previous point and not on earlier points is called a <strong>Markov Chain</strong>. We say the chain has a Markov property.</p>
<p><img alt="Markov Chain" src="_images/chain.png" /></p>
<p>If the distribution of chain points approximates the target distribution, we call the chain <strong>converged</strong>. This may require very long chains. Important technical terms are <strong>stationarity</strong> and <strong>ergodicity</strong>: stationary processes do not shift over time. Ergodicity is if the distribution within a long chain is the same as one random point taken from many chains. <img alt="Stationary" src="_images/stationary.png" /> <img alt="Ergodicity" src="_images/ergodicity.jpg" /></p>
<p>Because the algorithm will use random numbers to generate the next point in the Markov Chain (a Monte Carlo algorithm), it is a <strong>Markov Chain Monte Carlo</strong> (MCMC) algorithm.</p>
<p>The transition from one point to the next is called a <strong>transition kernel</strong>: <span class="math notranslate nohighlight">\(P(\theta_{i+1}|\theta_i)\)</span>. Each transition kernel gives a subclass of MCMC algorithms.</p>
<p>Here we will focus on transition kernels based on a <strong>Gaussian random walk</strong>:</p>
<p><span class="math notranslate nohighlight">\(\theta_{proposed} \sim Normal(\theta_i, \sigma)\)</span>:</p>
<p>In words, the next point is suggested by a Gaussian draw around the current point.</p>
<p><img alt="Gaussian proposal" src="_images/gaussian-proposal.jpg" /></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">mychain</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
<span class="n">proposal_sigma</span> <span class="o">=</span> <span class="mf">0.001</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">previous_point</span> <span class="o">=</span> <span class="n">mychain</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">proposed_point</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">previous_point</span><span class="p">,</span> <span class="n">proposal_sigma</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The final ingredient is the acceptance rule, to decide whether we stay with the current point or accept the proposed point. The rule is very simple and says:</p>
<p><em>We accept with a probability :math:`alpha`, which is the target probability ratio of the current to the proposed point</em>:</p>
<p><span class="math notranslate nohighlight">\(\alpha = p_\mathrm{accept} = \frac{f(\theta')}{f(\theta)}\)</span></p>
<p>This means there are three scenarios:</p>
<ul class="simple">
<li><p>The proposed point <span class="math notranslate nohighlight">\(\theta'\)</span> has a much, much lower probability than <span class="math notranslate nohighlight">\(\theta\)</span> -&gt; stay</p></li>
<li><p>The proposed point <span class="math notranslate nohighlight">\(\theta'\)</span> has a higher or equal probability than <span class="math notranslate nohighlight">\(\theta\)</span> -&gt; accept</p></li>
<li><p>The proposed point <span class="math notranslate nohighlight">\(\theta'\)</span> has a slightly lower probability than <span class="math notranslate nohighlight">\(\theta\)</span> -&gt; there is a chance we will accept.</p></li>
</ul>
<p>This is called the <strong>Metropolis algorithm</strong>. There is also an extension, the Metropolis-Hasting algorithm, for asymmetric transition kernels.</p>
<p>Lets implement our update rule:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">metropolis_algorithm</span><span class="p">(</span><span class="n">theta_new</span><span class="p">,</span> <span class="n">theta_old</span><span class="p">):</span>
    <span class="c1"># TODO by you:</span>
    <span class="n">prob_new</span> <span class="o">=</span> <span class="c1"># call loglikelihood using *theta_new, and convert to linear from ln</span>
    <span class="n">prob_old</span> <span class="o">=</span> <span class="c1"># call loglikelihood using *theta_old, and convert to linear from ln</span>

    <span class="n">alpha</span> <span class="o">=</span> <span class="c1"># take the ratio between prob_new and prob_old</span>

    <span class="c1"># draw randomly proportional to prob_ratio</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">u</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">Niter</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">Naccepts</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Niter</span><span class="p">):</span>

    <span class="c1"># get last point added to the chain</span>
    <span class="n">previous_point</span> <span class="o">=</span> <span class="n">mychain</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># pick a proposed point</span>
    <span class="n">proposed_point</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">previous_point</span><span class="p">,</span> <span class="n">proposal_sigma</span><span class="p">)</span>

    <span class="c1"># do we accept this point?</span>
    <span class="k">if</span> <span class="n">metropolis_algorithm</span><span class="p">(</span><span class="n">proposed_point</span><span class="p">,</span> <span class="n">previous_point</span><span class="p">):</span>
        <span class="n">Naccepts</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">next_point</span> <span class="o">=</span> <span class="n">proposed_point</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">next_point</span> <span class="o">=</span> <span class="n">previous_point</span>

    <span class="n">mychain</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_point</span><span class="p">)</span>

</pre></div>
</div>
</div>
<p>Lets already go ahead and make several chains, so we get a better feel for the typical behaviour:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">mcmc</span><span class="p">(</span><span class="n">starting_point</span><span class="p">,</span> <span class="n">Niter</span><span class="p">,</span> <span class="n">proposal_sigma</span><span class="p">):</span>
    <span class="n">Naccepts</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">chain</span> <span class="o">=</span> <span class="p">[</span><span class="n">starting_point</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Niter</span><span class="p">):</span>

        <span class="n">previous_point</span> <span class="o">=</span> <span class="n">chain</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">proposed_point</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">previous_point</span><span class="p">,</span> <span class="n">proposal_sigma</span><span class="p">)</span>

        <span class="c1"># do we accept this point?</span>
        <span class="k">if</span> <span class="n">metropolis_algorithm</span><span class="p">(</span><span class="n">proposed_point</span><span class="p">,</span> <span class="n">previous_point</span><span class="p">):</span>
            <span class="n">Naccepts</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">next_point</span> <span class="o">=</span> <span class="n">proposed_point</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">next_point</span> <span class="o">=</span> <span class="n">previous_point</span>

        <span class="n">chain</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_point</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Naccepts</span><span class="p">,</span> <span class="n">chain</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[54]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">chains_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">mcmc</span><span class="p">(</span><span class="n">starting_point</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Niter</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">proposal_sigma</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<p>Lets see how often the proposal was accepted, and a transition was made:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[55]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;acceptance rates: &quot;</span> <span class="o">+</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;</span><span class="si">%.1f%%</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">Naccepts</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">chain</span><span class="p">))</span> <span class="k">for</span> <span class="n">Naccepts</span><span class="p">,</span> <span class="n">chain</span> <span class="ow">in</span> <span class="n">chains_results</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
acceptance rates: 92.4%, 90.6%, 92.1%, 92.3%
</pre></div></div>
</div>
<p>As a rule of thumb for Metropolis MCMC:</p>
<ul class="simple">
<li><p>23% is ideal (unless in very low dimensions)</p></li>
<li><p>&gt;50% indicates the proposal is too small and the algorithm performs a levy-flight.</p></li>
<li><p>0% indicates the chain is stuck: The proposal is too wide and does not find good nearby points.</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[56]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">chains</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">chain</span> <span class="k">for</span> <span class="n">Naccepts</span><span class="p">,</span> <span class="n">chain</span> <span class="ow">in</span> <span class="n">chains_results</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="Visualisations">
<h1>Visualisations<a class="headerlink" href="#Visualisations" title="Permalink to this headline">¶</a></h1>
<div class="section" id="2d:-conditional-probability-distribution">
<h2>2d: conditional probability distribution<a class="headerlink" href="#2d:-conditional-probability-distribution" title="Permalink to this headline">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[57]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">chains</span><span class="p">[</span><span class="mi">0</span><span class="p">])[:,</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">chains</span><span class="p">[</span><span class="mi">0</span><span class="p">])[:,</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">chains</span><span class="p">[</span><span class="mi">0</span><span class="p">])),</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/3-Markov-Chain-Monte-Carlo_23_0.png" src="_images/3-Markov-Chain-Monte-Carlo_23_0.png" />
</div>
</div>
<div class="section" id="Trace-plots">
<h3>Trace plots<a class="headerlink" href="#Trace-plots" title="Permalink to this headline">¶</a></h3>
<p>For each parameter, plot iteration vs value:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[58]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dim</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

    <span class="c1"># TODO by you: plot all four chains instead of mychain</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">mychain</span><span class="p">)[:,</span><span class="n">i</span><span class="p">])</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Parameter </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Iteration&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/3-Markov-Chain-Monte-Carlo_26_0.png" src="_images/3-Markov-Chain-Monte-Carlo_26_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/3-Markov-Chain-Monte-Carlo_26_1.png" src="_images/3-Markov-Chain-Monte-Carlo_26_1.png" />
</div>
</div>
</div>
<div class="section" id="Marginal-probability-distribution">
<h3>Marginal probability distribution<a class="headerlink" href="#Marginal-probability-distribution" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[59]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dim</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

    <span class="c1"># TODO by you: plot all four chains instead of mychain</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">mychain</span><span class="p">)[:,</span><span class="n">i</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s1">&#39;step&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Parameter </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Number of samples&quot;</span><span class="p">)</span>

</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/3-Markov-Chain-Monte-Carlo_28_0.png" src="_images/3-Markov-Chain-Monte-Carlo_28_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/3-Markov-Chain-Monte-Carlo_28_1.png" src="_images/3-Markov-Chain-Monte-Carlo_28_1.png" />
</div>
</div>
</div>
</div>
</div>
<div class="section" id="Evaluation">
<h1>Evaluation<a class="headerlink" href="#Evaluation" title="Permalink to this headline">¶</a></h1>
<p>The trace plots show clearly that there is correlation between points.</p>
<p>Points are not independent, but <strong>correlated</strong>.</p>
<p>We can see this by splitting the chain into chunks:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[60]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">chain</span> <span class="o">=</span> <span class="n">chains</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">chain_chunks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">chain</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chain_chunks</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">chunk</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s1">&#39;step&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Parameter </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Number of samples&quot;</span><span class="p">)</span>

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/3-Markov-Chain-Monte-Carlo_31_0.png" src="_images/3-Markov-Chain-Monte-Carlo_31_0.png" />
</div>
</div>
<p>If the histograms are quite different between chunks, the chain has not converged.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[61]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">chain</span> <span class="ow">in</span> <span class="n">chains</span><span class="p">:</span>
        <span class="n">chain_chunks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">chain</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chain_chunks</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">chunk</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">xerr</span><span class="o">=</span><span class="n">chunk</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="n">y</span><span class="o">=</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
            <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">chain</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">xerr</span><span class="o">=</span><span class="n">chain</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="n">y</span><span class="o">=</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
        <span class="n">j</span> <span class="o">+=</span> <span class="mi">2</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Parameter </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Number of samples&quot;</span><span class="p">)</span>

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/3-Markov-Chain-Monte-Carlo_33_0.png" src="_images/3-Markov-Chain-Monte-Carlo_33_0.png" />
</div>
</div>
<p>Ideally, we want all of the markers (x and o) to line up.</p>
<p>We can quantify this by comparing the variance of the means within the chunks and across chains:</p>
<ul class="simple">
<li><p>Let <span class="math notranslate nohighlight">\(W\)</span> be the average of the chunk variances</p></li>
<li><p>Let <span class="math notranslate nohighlight">\(M_i\)</span> be the mean in chain i, and <span class="math notranslate nohighlight">\(M\)</span> the overall mean</p></li>
<li><p>Let <span class="math notranslate nohighlight">\(B\)</span> be the variance of M_ij: <span class="math notranslate nohighlight">\(B=\frac{1}{m-1}\sum_{i=1}^m (M_i - M)^2\)</span></p></li>
<li><p>Let <span class="math notranslate nohighlight">\(\hat{R} \approx \sqrt{1 + B/W}\)</span></p></li>
</ul>
<p>If the variances across chains are much smaller (<span class="math notranslate nohighlight">\(B\approx0\)</span>) than the variances within each chain (W), then <span class="math notranslate nohighlight">\(\hat{R}=1\)</span>. In other words, the means for each chain are comparable.</p>
<p>Deviations from 1 (e.g., &gt;1.01) are a sign that the chain has not converged.</p>
<p><img alt="Variance within a chain" src="_images/variance-within-chain.png" /></p>
<p><img alt="Variance between chains" src="_images/variance-between-chains.png" /></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[62]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dim</span><span class="p">):</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">chains</span><span class="p">[:,:,</span><span class="n">i</span><span class="p">])</span>

    <span class="n">chunk_variances</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">chain_variances</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">chain</span> <span class="ow">in</span> <span class="n">chains</span><span class="p">:</span>
        <span class="n">chain_variances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">chain</span><span class="p">[:,</span><span class="n">i</span><span class="p">]))</span>
        <span class="n">chain_chunks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">chain</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chain_chunks</span><span class="p">:</span>
            <span class="n">chunk_variances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="p">((</span><span class="n">chunk</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

    <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">chain_variances</span><span class="p">)</span>
    <span class="n">B</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">chunk_variances</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">chunk_variances</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;B:&quot;</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="s2">&quot;W:&quot;</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Rhat for Parameter </span><span class="si">%d</span><span class="s2">: </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">B</span><span class="o">/</span><span class="n">W</span><span class="p">)))</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
B: 0.0006125435020075697 W: 0.0007333165098014844
Rhat for Parameter 0: 1.35

B: 0.0003182154013342918 W: 0.0003374937287057879
Rhat for Parameter 1: 1.39

</pre></div></div>
</div>
<div class="section" id="Exercise-1-(30-points)">
<h2>Exercise 1 (30 points)<a class="headerlink" href="#Exercise-1-(30-points)" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Play with the number of MCMC iterations and the proposal standard deviation.</p></li>
<li><p>Observe the trace plots. What do you notice? Can you make Rhat=1?</p></li>
<li><p>Plot the Niter needed so that Rhat becomes &lt;1.01, for different values of sigma (0.1, 0.04, 0.01, for example).</p></li>
<li><p>Plot acceptance rate vs sigma.</p></li>
<li><p>Plot Niter vs sigma.</p></li>
</ul>
</div>
<div class="section" id="Exercise-2-(10-points)">
<h2>Exercise 2 (10 points)<a class="headerlink" href="#Exercise-2-(10-points)" title="Permalink to this headline">¶</a></h2>
<p>Try starting the chain at a random location in prior space.</p>
<p>The algorithm we used works in probabilities, but has numerical problems when they become smaller than 1e-330.</p>
<p>–&gt; Rewrite the MCMC algorithm to work with logarithmic probabilities only (never using exp).</p>
</div>
<div class="section" id="Homework-exercise-1-(20-points)">
<h2>Homework exercise 1 (20 points)<a class="headerlink" href="#Homework-exercise-1-(20-points)" title="Permalink to this headline">¶</a></h2>
<p>Find the <a class="reference external" href="https://emcee.readthedocs.io/en/stable/tutorials/autocorr/">auto-correlation length</a> of one of the chains.</p>
<p>Measure the effective sample size by dividing the number of samples by the auto-correlation length.</p>
</div>
<div class="section" id="Questions">
<h2>Questions<a class="headerlink" href="#Questions" title="Permalink to this headline">¶</a></h2>
<p>Related to efficiency: * What have you learned about the proposal distribution and auto-correlation? * Will a small proposal size give higher or lower correlation between points? * What proposal shape and size would be most efficient?</p>
<p>Related to using the output of MCMC algorithms: * How would you use the marginal histograms to get parameter uncertainties? * If the chain is not converged, what would a user of a single chain conclude about the credible interval? What could go wrong? * How did we compute the Bayesian evidence (normalising factor)? * Is convergence defined for the chain globally, or for each parameter?</p>
</div>
<div class="section" id="Homework-exercise-2-(60-points)">
<h2>Homework exercise 2 (60 points)<a class="headerlink" href="#Homework-exercise-2-(60-points)" title="Permalink to this headline">¶</a></h2>
<p>Set up a target density which sums two Gaussians:</p>
<p><span class="math notranslate nohighlight">\(f(\theta)=\mathrm{NormalPDF}(\theta|\mu=-\Delta,\sigma=1) + \mathrm{NormalPDF}(\theta|\mu=+\Delta,\sigma=1).\)</span></p>
<p>Plot <span class="math notranslate nohighlight">\(\Delta\)</span> vs the number of iterations needed for convergence, for 2d and 20d.</p>
<p>Starting the chains at random locations.</p>
</div>
<div class="section" id="Further-reading">
<h2>Further reading<a class="headerlink" href="#Further-reading" title="Permalink to this headline">¶</a></h2>
<p>MCMC is a very mature field and its algorithmic variants have been studied for &gt;50 years.</p>
<p>There are lots of resources (slides, papers, tutorials) online, just search for “intro/tutorial to MCMC”.</p>
<p>Gaussian Random Walk Metropolis MCMC is quite inefficient in moderate dimensions (&gt;5), even with optimally adapted proposals.</p>
<p>Important MCMC variants:</p>
<ul class="simple">
<li><p>Gibbs sampling: analytic conditional distributions allow 100% efficient updates of one parameter.</p></li>
<li><p>Slice sampling</p></li>
<li><p>Simulated tempering, Parallel tempering: make chain easier to navigate by suppressing the likelihod <span class="math notranslate nohighlight">\(L^{\beta}, \beta=0...1\)</span>.</p></li>
<li><p>Ensemble updates: Maintain several walkers (chains) and update them all</p>
<ul>
<li><p>Differential Evolution MCMC</p></li>
<li><p>Goodman Weare, aka, Affine-Invariant Ensemble sampler</p>
<ul>
<li><p><a class="reference external" href="https://emcee.readthedocs.io/">emcee</a> implementation extremely popular in astronomy</p></li>
<li><p>Sensitive to initialisation, two tuning parameters: number of walkers and gamma.</p></li>
<li><p>Beware of bad behaviour in high-d: <a class="reference external" href="https://arxiv.org/abs/1509.02230">https://arxiv.org/abs/1509.02230</a></p></li>
</ul>
</li>
<li><p>Ensemble Slice Sampling (zeus)</p>
<ul>
<li><p><a class="reference external" href="https://zeus-mcmc.readthedocs.io/">zeus</a> implementation, similar use as emcee</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Reversible Jump MCMC: allows varying dimensionality. Difficult to work with.</p></li>
<li><p>Hamiltonian Monte Carlo: Uses likelihood gradients to make trajectories. Efficient in high dimensions.</p></li>
</ul>
<p>Diagnostics:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arviz-devs.github.io/arviz/">https://arviz-devs.github.io/arviz/</a></p></li>
<li><p>CODA R package</p></li>
<li><p>state-of-the-art R-hat paper: <a class="reference external" href="https://arxiv.org/abs/1903.08008">https://arxiv.org/abs/1903.08008</a></p></li>
</ul>
<p>Conceptual introduction: <a class="reference external" href="https://arxiv.org/pdf/1701.02434.pdf">https://arxiv.org/pdf/1701.02434.pdf</a></p>
</div>
</div>
<div class="section" id="Ticket-to-leave">
<h1>Ticket to leave<a class="headerlink" href="#Ticket-to-leave" title="Permalink to this headline">¶</a></h1>
<p>Fill out the <a class="reference external" href="https://indico.ph.tum.de/event/6875/surveys/8">form below</a> and then you can leave the class. (+5 points)</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[67]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%html</span>

<span class="p">&lt;</span><span class="nt">iframe</span> <span class="na">src</span><span class="o">=</span><span class="s">&quot;https://indico.ph.tum.de/event/6875/surveys/8&quot;</span> <span class="na">style</span><span class="o">=</span><span class="s">&quot;width: 100%; height: 400px&quot;</span><span class="p">&gt;&lt;/</span><span class="nt">iframe</span><span class="p">&gt;</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<iframe src="https://indico.ph.tum.de/event/6875/surveys/8" style="width: 100%; height: 400px"></iframe></div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Johannes Buchner, Francesca Capel

    </p>
  </div> 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>